{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataH5():\n",
    "    with h5py.File('data1.h5','r') as hf: \n",
    "        trainX = np.array(hf.get('trainX')) \n",
    "        trainY = np.array(hf.get('trainY')) \n",
    "        valX = np.array(hf.get('valX')) \n",
    "        valY = np.array(hf.get('valY')) \n",
    "        print (trainX.shape,trainY.shape) \n",
    "        print (valX.shape,valY.shape)\n",
    "    return trainX, trainY, valX, valY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showGraph(Histroy, epochs):\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), Histroy.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, epochs), Histroy.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, epochs), Histroy.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, epochs), Histroy.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, epochs, trainX, trainY, testX, testY):\n",
    "\n",
    "    print (trainX.shape,trainY.shape)\n",
    "    print (testX.shape,testY.shape)\n",
    "    opt = tf.keras.optimizers.SGD(lr=0.01)\n",
    "    print (model.summary())\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    print(\"Training network...\")\n",
    "    H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "        batch_size=32, epochs=epochs)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a baseline CNN, which contains just a single convolutional layer, single pooling layer, fully connected layer and softmax layer.\n",
    "# Increase the number of layers in your CNN (the number of convolutional and pooling layers). You should implement at least three different CNN configurations (not including the baseline). In your report show the impact on the validation and training accuracy/loss values (inclusive of the baseline case). Compare and contrast the performance of your models in your report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 128, 128, 3) (1020,)\n",
      "(340, 128, 128, 3) (340,)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY, valX, valY = loadDataH5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = trainX.shape[1:]\n",
    "classes = 17\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_CNN = tf.keras.Sequential() \n",
    "baseline_CNN.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\", input_shape=input_shape, activation='relu'))\n",
    "baseline_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "baseline_CNN.add(tf.keras.layers.Flatten())\n",
    "baseline_CNN.add(Dense(64, activation = \"relu\")) # making the model fully connected\n",
    "baseline_CNN.add(tf.keras.layers.Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = trainModel(baseline_CNN, epochs, trainX, trainY, valX, valY)\n",
    "# showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN2 = tf.keras.Sequential() \n",
    "CNN2.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\", input_shape=input_shape, activation='relu'))\n",
    "CNN2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN2.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "CNN2.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    \n",
    "CNN2.add(tf.keras.layers.Flatten())\n",
    "CNN2.add(Dense(256, activation = \"relu\")) # making the model fully connected\n",
    "CNN2.add(tf.keras.layers.Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = trainModel(CNN2, epochs, trainX, trainY, valX, valY)\n",
    "# showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN3 = tf.keras.Sequential() \n",
    "CNN3.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\", input_shape=input_shape, activation='relu'))\n",
    "CNN3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN3.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "CNN3.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "\n",
    "CNN3.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "CNN3.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "\n",
    "\n",
    "CNN3.add(tf.keras.layers.Flatten())\n",
    "CNN3.add(Dense(512, activation = \"relu\")) # making the model fully connected\n",
    "CNN3.add(tf.keras.layers.Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = trainModel(CNN3, epochs, trainX, trainY, valX, valY)\n",
    "# showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN4 = tf.keras.Sequential() \n",
    "CNN4.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\", input_shape=input_shape, activation='relu'))\n",
    "CNN4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN4.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "CNN4.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "\n",
    "CNN4.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "CNN4.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "CNN4.add(Conv2D(filters = 512, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "CNN4.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    \n",
    "CNN4.add(tf.keras.layers.Flatten())\n",
    "CNN4.add(Dense(1024, activation = \"relu\")) # making the model fully connected\n",
    "CNN4.add(tf.keras.layers.Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = trainModel(CNN4, epochs, trainX, trainY, valX, valY)\n",
    "# showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the implementation of data augmentation techniques for two of the above models (please select the two deepest models). \n",
    "# In your report describe the impact(if any), of applying data augmentation on these models. \n",
    "# How do you explain the impact of data augmentation? Does the selection of methods used as part of your data augmentation (such as cropping, flipping etc) have an influence on accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelAug(model, datagen, epochs, trainX, trainY, testX, testY):\n",
    "\n",
    "    print (trainX.shape,trainY.shape)\n",
    "    print (testX.shape,testY.shape)\n",
    "    opt = tf.keras.optimizers.SGD(lr=0.01)\n",
    "    print (model.summary())\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    print(\"Training network...\")\n",
    "    H = model.fit_generator(\n",
    "                      datagen.flow(trainX, trainY,batch_size=32),\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(valX,valY))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 128, 128, 3) (1020,)\n",
      "(340, 128, 128, 3) (340,)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY, testX, testY = loadDataH5()\n",
    "input_shape = trainX.shape[1:]\n",
    "classes = 17\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainModelAug(CNN3, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainModelAug(CNN4, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do you explain the impact of data augmentation? Does the selection of methods used as part of your data augmentation (such as cropping, flipping etc) have an influence on accuracy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding more aggresive data augmentation parameters on the deepest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=90, \n",
    "                                   width_shift_range=[0.1,0.5],\n",
    "                                   height_shift_range=[0.1,0.5], \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=[0.1,0.5],\n",
    "                                   horizontal_flip=True,\n",
    "                                   brightness_range=[0.2,0.5],\n",
    "                                   fill_mode=\"nearest\")\n",
    "train_datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainModelAug(CNN4, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=90, \n",
    "                                   width_shift_range=[0.1,0.5],\n",
    "                                   height_shift_range=[0.1,0.5], \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=[0.1,0.5],\n",
    "                                   horizontal_flip=True,\n",
    "                                   brightness_range=[0.2,0.5],\n",
    "                                   fill_mode=\"nearest\")\n",
    "train_datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainModelAug(CNN3, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removed few data augmentation parameters on the deepest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=[0.1,1],\n",
    "                                   horizontal_flip=True,\n",
    "                                   brightness_range=[0.2,1.0],\n",
    "                                   fill_mode=\"nearest\")\n",
    "train_datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainModelAug(CNN4, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 128, 128, 3) (1020,)\n",
      "(340, 128, 128, 3) (340,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               33554944  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 17)                8721      \n",
      "=================================================================\n",
      "Total params: 33,934,481\n",
      "Trainable params: 33,934,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training network...\n",
      "WARNING:tensorflow:From <ipython-input-16-31403606c5b4>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 32 steps, validate on 340 samples\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 24s 751ms/step - loss: nan - accuracy: 0.0627 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 24s 743ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 23s 721ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 24s 741ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 24s 737ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 23s 716ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 23s 726ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 23s 727ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 23s 719ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 23s 733ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 24s 752ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 24s 750ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 24s 737ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 23s 728ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 23s 720ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 24s 740ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 23s 728ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 23s 734ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 23s 730ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 24s 742ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 23s 733ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 24s 761ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 23s 733ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 23s 725ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 24s 750ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 24s 744ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 23s 719ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 24s 749ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 23s 726ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 23s 721ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 24s 735ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 23s 730ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 24s 738ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 23s 724ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 24s 737ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 23s 721ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 23s 725ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 24s 739ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 23s 722ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 23s 726ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 23s 711ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 23s 731ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 24s 744ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 23s 723ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 23s 714ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 24s 739ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 23s 722ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 24s 747ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 23s 728ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 23s 726ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 23s 703ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 23s 711ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 23s 721ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 23s 722ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 23s 709ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 23s 727ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 23s 708ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 23s 727ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 23s 723ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 23s 722ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 24s 734ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 24s 737ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 23s 720ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 23s 730ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 23s 732ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 23s 711ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 23s 723ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 23s 730ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 23s 731ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 23s 719ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 23s 728ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 23s 720ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 23s 720ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 23s 725ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 23s 727ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 23s 734ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 23s 725ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 23s 717ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 23s 718ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 23s 716ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 24s 745ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 23s 709ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 23s 720ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 23s 726ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 23s 729ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 23s 732ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 23s 721ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 23s 733ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 23s 715ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 23s 725ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 23s 723ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 23s 719ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 23s 715ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 23s 730ms/step - loss: nan - accuracy: 0.0598 - val_loss: nan - val_accuracy: 0.0559\n",
      "Epoch 95/100\n",
      "15/32 [=============>................] - ETA: 11s - loss: nan - accuracy: 0.0646"
     ]
    }
   ],
   "source": [
    "history = trainModelAug(CNN3, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making data augmentation more subtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=45,\n",
    "                                   horizontal_flip=True,\n",
    "                                   brightness_range=[0.2,1.0])\n",
    "train_datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 128, 128, 3) (1020,)\n",
      "(340, 128, 128, 3) (340,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 17)                17425     \n",
      "=================================================================\n",
      "Total params: 35,123,857\n",
      "Trainable params: 35,123,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 32 steps, validate on 340 samples\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0252 - accuracy: 0.7422 - val_loss: 2.7698 - val_accuracy: 0.0735\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5521 - accuracy: 0.8324 - val_loss: 2.7733 - val_accuracy: 0.0706\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.5769 - accuracy: 0.8422 - val_loss: 2.7860 - val_accuracy: 0.1029\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4803 - accuracy: 0.8618 - val_loss: 2.7661 - val_accuracy: 0.0853\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4661 - accuracy: 0.8725 - val_loss: 2.7571 - val_accuracy: 0.0912\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4347 - accuracy: 0.8725 - val_loss: 2.7336 - val_accuracy: 0.1294\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3054 - accuracy: 0.9196 - val_loss: 2.7435 - val_accuracy: 0.1441\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3330 - accuracy: 0.9088 - val_loss: 2.7399 - val_accuracy: 0.1147\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3981 - accuracy: 0.8980 - val_loss: 2.7494 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2352 - accuracy: 0.9324 - val_loss: 2.7154 - val_accuracy: 0.1059\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2185 - accuracy: 0.9373 - val_loss: 2.7054 - val_accuracy: 0.0882\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2655 - accuracy: 0.9333 - val_loss: 2.6834 - val_accuracy: 0.1324\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1737 - accuracy: 0.9529 - val_loss: 2.6870 - val_accuracy: 0.1294\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1809 - accuracy: 0.9500 - val_loss: 2.6813 - val_accuracy: 0.1206\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1481 - accuracy: 0.9559 - val_loss: 2.6621 - val_accuracy: 0.1647\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1824 - accuracy: 0.9539 - val_loss: 2.6489 - val_accuracy: 0.1618\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1669 - accuracy: 0.9539 - val_loss: 2.6611 - val_accuracy: 0.1647\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1100 - accuracy: 0.9735 - val_loss: 2.6654 - val_accuracy: 0.1529\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0265 - accuracy: 0.7853 - val_loss: 2.7171 - val_accuracy: 0.1088\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2690 - accuracy: 0.9353 - val_loss: 2.6843 - val_accuracy: 0.0971\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1562 - accuracy: 0.9627 - val_loss: 2.6714 - val_accuracy: 0.1382\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.1295 - accuracy: 0.9647 - val_loss: 2.6606 - val_accuracy: 0.1382\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1251 - accuracy: 0.9745 - val_loss: 2.6720 - val_accuracy: 0.1412\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.1388 - accuracy: 0.9657 - val_loss: 2.6210 - val_accuracy: 0.1676\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.1715 - accuracy: 0.9598 - val_loss: 2.6544 - val_accuracy: 0.1353\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.1201 - accuracy: 0.9676 - val_loss: 2.6251 - val_accuracy: 0.1882\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1284 - accuracy: 0.9637 - val_loss: 2.6438 - val_accuracy: 0.1735\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1221 - accuracy: 0.9667 - val_loss: 2.6548 - val_accuracy: 0.1324\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0543 - accuracy: 0.9873 - val_loss: 2.6259 - val_accuracy: 0.1735\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0396 - accuracy: 0.9931 - val_loss: 2.6483 - val_accuracy: 0.1559\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2517 - accuracy: 0.9500 - val_loss: 2.6620 - val_accuracy: 0.1206\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1294 - accuracy: 0.9706 - val_loss: 2.6390 - val_accuracy: 0.1588\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0973 - accuracy: 0.9775 - val_loss: 2.6451 - val_accuracy: 0.1735\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0621 - accuracy: 0.9873 - val_loss: 2.6212 - val_accuracy: 0.1588\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.1458 - accuracy: 0.9559 - val_loss: 2.6635 - val_accuracy: 0.1471\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.2430 - accuracy: 0.9343 - val_loss: 2.6566 - val_accuracy: 0.1441\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.1309 - accuracy: 0.9647 - val_loss: 2.6171 - val_accuracy: 0.1765\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.0501 - accuracy: 0.9873 - val_loss: 2.6039 - val_accuracy: 0.1824\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1382 - accuracy: 0.9696 - val_loss: 2.6267 - val_accuracy: 0.1471\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 2.6110 - val_accuracy: 0.2000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0218 - accuracy: 0.9971 - val_loss: 2.6091 - val_accuracy: 0.1794\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0262 - accuracy: 0.9951 - val_loss: 2.5971 - val_accuracy: 0.1882\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.0235 - accuracy: 0.9961 - val_loss: 2.5815 - val_accuracy: 0.2059\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 2.5632 - val_accuracy: 0.2324\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0272 - accuracy: 0.9931 - val_loss: 2.5820 - val_accuracy: 0.2147\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.0435 - accuracy: 0.9922 - val_loss: 2.5829 - val_accuracy: 0.1706\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0436 - accuracy: 0.9892 - val_loss: 2.5728 - val_accuracy: 0.2235\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1155 - accuracy: 0.9735 - val_loss: 2.5569 - val_accuracy: 0.2324\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0419 - accuracy: 0.9902 - val_loss: 2.5660 - val_accuracy: 0.2059\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0409 - accuracy: 0.9922 - val_loss: 2.5649 - val_accuracy: 0.2382\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 2.5486 - val_accuracy: 0.2382\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.3108 - accuracy: 0.7441 - val_loss: 2.7124 - val_accuracy: 0.1441\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4591 - accuracy: 0.8853 - val_loss: 2.6706 - val_accuracy: 0.1676\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.1416 - accuracy: 0.9696 - val_loss: 2.6439 - val_accuracy: 0.1500\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0809 - accuracy: 0.9794 - val_loss: 2.6080 - val_accuracy: 0.2235\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1108 - accuracy: 0.9755 - val_loss: 2.6038 - val_accuracy: 0.2235\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.2566 - accuracy: 0.9422 - val_loss: 2.6590 - val_accuracy: 0.1500\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0912 - accuracy: 0.9765 - val_loss: 2.6110 - val_accuracy: 0.2441\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1751 - accuracy: 0.9549 - val_loss: 2.6281 - val_accuracy: 0.2147\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0662 - accuracy: 0.9824 - val_loss: 2.6037 - val_accuracy: 0.2206\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0470 - accuracy: 0.9892 - val_loss: 2.5802 - val_accuracy: 0.2588\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0644 - accuracy: 0.9863 - val_loss: 2.5851 - val_accuracy: 0.2412\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0393 - accuracy: 0.9941 - val_loss: 2.5814 - val_accuracy: 0.2529\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0634 - accuracy: 0.9833 - val_loss: 2.5726 - val_accuracy: 0.2559\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1535 - accuracy: 0.9696 - val_loss: 2.6051 - val_accuracy: 0.2088\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3172 - accuracy: 0.9549 - val_loss: 2.6360 - val_accuracy: 0.1735\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.1724 - accuracy: 0.9608 - val_loss: 2.6139 - val_accuracy: 0.2147\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0423 - accuracy: 0.9931 - val_loss: 2.5874 - val_accuracy: 0.2324\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 2.5698 - val_accuracy: 0.2765\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0733 - accuracy: 0.9853 - val_loss: 2.5851 - val_accuracy: 0.2294\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0807 - accuracy: 0.9794 - val_loss: 2.5739 - val_accuracy: 0.2588\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0877 - accuracy: 0.9804 - val_loss: 2.6021 - val_accuracy: 0.2206\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0664 - accuracy: 0.9843 - val_loss: 2.5753 - val_accuracy: 0.2588\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 2.5724 - val_accuracy: 0.2235\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 2.5672 - val_accuracy: 0.2647\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 2.5519 - val_accuracy: 0.3000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0389 - accuracy: 0.9941 - val_loss: 2.5590 - val_accuracy: 0.2941\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1621 - accuracy: 0.9706 - val_loss: 2.5798 - val_accuracy: 0.2441\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0422 - accuracy: 0.9892 - val_loss: 2.5739 - val_accuracy: 0.2559\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0517 - accuracy: 0.9892 - val_loss: 2.5769 - val_accuracy: 0.2324\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 2.5480 - val_accuracy: 0.2706\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 2.5438 - val_accuracy: 0.2676\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 2.5379 - val_accuracy: 0.2735\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 2.5341 - val_accuracy: 0.2794\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0303 - accuracy: 0.9892 - val_loss: 2.5441 - val_accuracy: 0.2500\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: 2.5364 - val_accuracy: 0.2706\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 2.5273 - val_accuracy: 0.2853\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.5179 - val_accuracy: 0.2971\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5170 - val_accuracy: 0.2971\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 2.5131 - val_accuracy: 0.3118\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5042 - val_accuracy: 0.3147\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0259 - accuracy: 0.9961 - val_loss: 2.5143 - val_accuracy: 0.3059\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 2.5001 - val_accuracy: 0.3676\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0532 - accuracy: 0.9873 - val_loss: 2.5053 - val_accuracy: 0.3676\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.1202 - accuracy: 0.9716 - val_loss: 2.5469 - val_accuracy: 0.2706\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0180 - accuracy: 0.9961 - val_loss: 2.5490 - val_accuracy: 0.2294\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0285 - accuracy: 0.9941 - val_loss: 2.5416 - val_accuracy: 0.2500\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 2.5426 - val_accuracy: 0.2618\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 2.5261 - val_accuracy: 0.2941\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0214 - accuracy: 0.9961 - val_loss: 2.5176 - val_accuracy: 0.3088\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = trainModelAug(CNN4, train_datagen, 100, trainX, trainY, testX, testY)\n",
    "showGraph(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
